{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 1: Preprocess VNG's data\n",
    "In this stage, we will read raw data from a given dataset. The dataset consists of variable-resolution images, while our system requires a constant input dimensionality. Therefore, we need to down-sampled the images to a fixed resolution (270 x 270)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples of processing\n",
    " + In the bellow code, we will crop the central region of raw image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "from scipy.misc import imread, imresize\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "raw_image = imread('model/datasets/nudity_dataset/3.jpg')\n",
    "\n",
    "# Define a tensor placeholder to store an image\n",
    "image = tf.placeholder(\"uint8\", [None, None, 3])\n",
    "image1 = tf.image.convert_image_dtype(image, dtype=tf.float32)\n",
    "image2 = tf.image.central_crop(image1, central_fraction=0.875) # Crop the central region of raw image\n",
    "\n",
    "model = tf.initialize_all_variables() # Quan trong\n",
    "\n",
    "print raw_image.shape\n",
    "with tf.Session() as session:\n",
    "    session.run(model)\n",
    "    result = session.run(image2, feed_dict={image: raw_image})\n",
    "    print result.dtype\n",
    "    print(\"The shape of result: \",result.shape)\n",
    "\n",
    "print result.shape\n",
    "## Draw image\n",
    "fig = plt.figure()\n",
    "a = fig.add_subplot(1,2,1)\n",
    "plt.imshow(raw_image)\n",
    "a = fig.add_subplot(1,2,2)\n",
    "plt.imshow(result)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ In the code bellow, resize image into the special resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.misc import imread, imresize\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "raw_image = imread('model/datasets/nudity_dataset/3.jpg')\n",
    "\n",
    "image = tf.placeholder(\"uint8\", [None, None, 3])\n",
    "image1 = tf.image.convert_image_dtype(image, dtype = tf.float32)\n",
    "image1_t = tf.expand_dims(image1, 0)\n",
    "image2 = tf.image.resize_bilinear(image1_t, [270, 270], align_corners=False)\n",
    "image2 = tf.squeeze(image2, [0])\n",
    "\n",
    "image3 = tf.sub(image2, 0.5)\n",
    "image3 = tf.mul(image2, 2.0)\n",
    "\n",
    "model = tf.initialize_all_variables()\n",
    "\n",
    "with tf.Session() as session:\n",
    "    session.run(model)\n",
    "    result = session.run(image3, feed_dict={image:raw_image})\n",
    "\n",
    "## Draw image\n",
    "fig = plt.figure()\n",
    "a = fig.add_subplot(1,2,1)\n",
    "plt.imshow(raw_image)\n",
    "a = fig.add_subplot(1,2,2)\n",
    "plt.imshow(result)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.1 Create a standard training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import tensorflow  as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cPickle as pickle\n",
    "from model.datasets.data import generate_standard_dataset\n",
    "\n",
    "# Load Normal and Nude images into the train dataset\n",
    "\n",
    "image_normal_ls, file_name_normal = generate_standard_dataset('/home/cpu11757/workspace/Nudity_Detection/src/model/datasets/train/normal')\n",
    "\n",
    "nudity_ls, file_name_nudity = generate_standard_dataset('/home/cpu11757/workspace/Nudity_Detection/src/model/datasets/train/nude')\n",
    "\n",
    "init_op = tf.initialize_all_variables()\n",
    "\n",
    "labels = np.zeros(3000, dtype = np.uint)\n",
    "\n",
    "\n",
    "database = []\n",
    "with tf.Session() as session:\n",
    "    session.run(init_op)\n",
    "    # Start populating the filename queue\n",
    "    coord = tf.train.Coordinator()\n",
    "    tf.train.start_queue_runners(coord=coord)    \n",
    "    for i in range(3000):\n",
    "        #print i\n",
    "        if i % 2 == 0:\n",
    "            image = image_normal_ls.eval()\n",
    "        else:\n",
    "            image = nudity_ls.eval()\n",
    "            labels[i] = 1\n",
    "        database.append(image)\n",
    "    coord.request_stop()\n",
    "\n",
    "database = np.array(database)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from Dataset.data import generate_standard_dataset\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "img_nudity, _ = generate_standard_dataset('/media/taivu/Data/Project/Nudity_Detection/src/model/datasets/AdditionalDataset/vng/sex')\n",
    "\n",
    "labels = np.ones(100, dtype = np.uint)\n",
    "\n",
    "dataset = []\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    coord = tf.train.Coordinator()\n",
    "    tf.train.start_queue_runners(coord=coord)\n",
    "    \n",
    "    for i in range(100):\n",
    "        image = img_nudity.eval()\n",
    "        dataset.append(image)\n",
    "    coord.request_stop()\n",
    "    \n",
    "database = np.array(dataset)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print file_name_normal[1123]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Generate tfrecords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "def _int64_feature(value):\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "\n",
    "def _bytes_feature(value):\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "def convert_to(data_dir, dataset, labels, name):\n",
    "    \"\"\"Converts a dataset to tfrecords.\"\"\"\n",
    "    images = dataset\n",
    "    labels = labels\n",
    "    num_examples = dataset.shape[0]\n",
    "    \n",
    "    rows, cols, depth = dataset[0].shape\n",
    "    \n",
    "    filename = os.path.join(data_dir, name + '.tfrecords')\n",
    "    \n",
    "    writer = tf.python_io.TFRecordWriter(filename)\n",
    "    \n",
    "    for idx in range(num_examples):\n",
    "        image_raw = images[idx].tostring()\n",
    "        example = tf.train.Example(features = tf.train.Features(feature={\n",
    "                    'height': _int64_feature(rows),\n",
    "                    'width': _int64_feature(cols),\n",
    "                    'depth': _int64_feature(depth),\n",
    "                    'label': _int64_feature(int(labels[idx])),\n",
    "                    'image_raw': _bytes_feature(image_raw)\n",
    "                }))\n",
    "        writer.write(example.SerializeToString())\n",
    "    writer.close()\n",
    "\n",
    "convert_to('/home/taivu/workspace/NudityDetection/Dataset',\n",
    "          database, labels, 'nudity_test_set')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+  Read a batch images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def read_and_decode(filename_queue):\n",
    "    reader = tf.TFRecordReader()\n",
    "    _, serialized_example = reader.read(filename_queue)\n",
    "    features = tf.parse_single_example(\n",
    "    serialized_example,\n",
    "    features={\n",
    "            'image_raw': tf.FixedLenFeature([], tf.string),\n",
    "            'label': tf.FixedLenFeature([], tf.int64),\n",
    "            'depth': tf.FixedLenFeature([], tf.int64),\n",
    "            'width': tf.FixedLenFeature([], tf.int64),\n",
    "            'height': tf.FixedLenFeature([], tf.int64)\n",
    "        })\n",
    "    \n",
    "    image = tf.decode_raw(features['image_raw'], tf.float32)\n",
    "    image = tf.reshape(image,[34,34,3])\n",
    "    label = tf.cast(features['label'], tf.int32)\n",
    "    height = tf.cast(features['height'], tf.int32)\n",
    "    width = tf.cast(features['width'], tf.int32)\n",
    "    depth = tf.cast(features['depth'], tf.int32)\n",
    "    return image, label, height, width, depth\n",
    "\n",
    "def data_input(data_dir, batch_size):\n",
    "    filename_queue = tf.train.string_input_producer([data_dir], num_epochs = None)\n",
    "    image, label, height, width, depth = read_and_decode(filename_queue)\n",
    "    \n",
    "    images_batch, labels_batch = tf.train.shuffle_batch(\n",
    "        [image, label], \n",
    "        batch_size = batch_size,\n",
    "        capacity = 2000,\n",
    "        min_after_dequeue = 80\n",
    "    )\n",
    "    return images_batch, labels_batch\n",
    "\n",
    "\n",
    "#filename_queue = tf.train.string_input_producer(['/home/cpu11757/workspace/Nudity_Detection/src/model/datasets/vng_dataset.tfrecords'], num_epochs = None)\n",
    "#image, label, height,_,depth = read_and_decode(filename_queue)\n",
    "img_batch, lb_batch = data_input('/home/cpu11757/workspace/Nudity_Detection/src/model/datasets/vng_dataset.tfrecords',500)\n",
    "\n",
    "init_op = tf.initialize_all_variables()\n",
    "fig = plt.figure()\n",
    "\n",
    "with tf.Session() as session:\n",
    "    session.run(init_op)\n",
    "    coord = tf.train.Coordinator()\n",
    "    tf.train.start_queue_runners(coord=coord)\n",
    "    images, labels = session.run([img_batch, lb_batch])\n",
    "    coord.request_stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.imshow(images[1])\n",
    "print labels[0]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Example shuffle dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "f = [\"f1\", \"f2\", \"f3\", \"f4\", \"f5\", \"f6\", \"f7\", \"f8\"]\n",
    "l = [\"l1\", \"l2\", \"l3\", \"l4\", \"l5\", \"l6\", \"l7\", \"l8\"]\n",
    "\n",
    "fv = tf.constant(f)\n",
    "lv = tf.constant(l)\n",
    "\n",
    "rsq = tf.RandomShuffleQueue(10, 0, [tf.string, tf.string], shapes=[[],[]])\n",
    "do_enqueues = rsq.enqueue_many([fv, lv])\n",
    "\n",
    "gotf, gotl = rsq.dequeue()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.initialize_all_variables())\n",
    "    coord = tf.train.Coordinator()\n",
    "    tf.train.start_queue_runners(sess=sess,coord = coord)\n",
    "    sess.run(do_enqueues)\n",
    "    for i in xrange(2):\n",
    "        one_f, one_l = sess.run([gotf, gotl])\n",
    "        print \"F: \", one_f, \"L: \", one_l\n",
    "    \n",
    "    coord.request_stop()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Example cPickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cPickle as pickle\n",
    "\n",
    "dict1 = {'name':[],'id':[]}\n",
    "dict2 = {'local':[], 'paza':[]}\n",
    "\n",
    "#with open('test.p', 'wb') as fp:\n",
    "#    pickle.dump(dict1,fp)\n",
    "#    pickle.dump(dict2,fp)\n",
    "    \n",
    "with open('test.p', 'rb') as fp:\n",
    "    d1 = pickle.load(fp)\n",
    "    d2 = pickle.load(fp)\n",
    "\n",
    "print len(d1)\n",
    "print len(d2)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Example reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "a = tf.constant(np.array([[.1]]))\n",
    "init = tf.initialize_all_variables()\n",
    "with tf.Session() as session:\n",
    "    session.run(init)\n",
    "    b = session.run(tf.nn.softmax(a))\n",
    "    c = session.run(tf.nn.softmax_cross_entropy_with_logits([0.6, 0.4],[0,1]))\n",
    "    #print b\n",
    "    #print c\n",
    "\n",
    "label = np.array([[0], [1], [1]])\n",
    "idx = np.arange(3) * 2\n",
    "print ('IDX')\n",
    "print idx\n",
    "\n",
    "labels_one_hot = np.zeros((3,2))\n",
    "print ('labels_one_hot')\n",
    "print labels_one_hot\n",
    "\n",
    "\n",
    "labels_one_hot.flat[idx + label.ravel()] = 1\n",
    "print ('IDX + label.ravel()')\n",
    "print idx + label.ravel()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
