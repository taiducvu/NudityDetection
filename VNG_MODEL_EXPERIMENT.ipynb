{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 1: Preprocess VNG's data\n",
    "In this stage, we will read raw data from a given dataset. The dataset consists of variable-resolution images, while our system requires a constant input dimensionality. Therefore, we need to down-sampled the images to a fixed resolution (270 x 270)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples of processing\n",
    " + In the bellow code, we will crop the central region of raw image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "from scipy.misc import imread, imresize\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "raw_image = imread('model/datasets/nudity_dataset/3.jpg')\n",
    "\n",
    "# Define a tensor placeholder to store an image\n",
    "image = tf.placeholder(\"uint8\", [None, None, 3])\n",
    "image1 = tf.image.convert_image_dtype(image, dtype=tf.float32)\n",
    "image2 = tf.image.central_crop(image1, central_fraction=0.875) # Crop the central region of raw image\n",
    "\n",
    "model = tf.initialize_all_variables() # Quan trong\n",
    "\n",
    "print raw_image.shape\n",
    "with tf.Session() as session:\n",
    "    session.run(model)\n",
    "    result = session.run(image2, feed_dict={image: raw_image})\n",
    "    print result.dtype\n",
    "    print(\"The shape of result: \",result.shape)\n",
    "\n",
    "print result.shape\n",
    "## Draw image\n",
    "fig = plt.figure()\n",
    "a = fig.add_subplot(1,2,1)\n",
    "plt.imshow(raw_image)\n",
    "a = fig.add_subplot(1,2,2)\n",
    "plt.imshow(result)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ In the code bellow, resize image into the special resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.misc import imread, imresize\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "raw_image = imread('model/datasets/nudity_dataset/3.jpg')\n",
    "\n",
    "image = tf.placeholder(\"uint8\", [None, None, 3])\n",
    "image1 = tf.image.convert_image_dtype(image, dtype = tf.float32)\n",
    "image1_t = tf.expand_dims(image1, 0)\n",
    "image2 = tf.image.resize_bilinear(image1_t, [270, 270], align_corners=False)\n",
    "image2 = tf.squeeze(image2, [0])\n",
    "\n",
    "image3 = tf.sub(image2, 0.5)\n",
    "image3 = tf.mul(image2, 2.0)\n",
    "\n",
    "model = tf.initialize_all_variables()\n",
    "\n",
    "with tf.Session() as session:\n",
    "    session.run(model)\n",
    "    result = session.run(image3, feed_dict={image:raw_image})\n",
    "\n",
    "## Draw image\n",
    "fig = plt.figure()\n",
    "a = fig.add_subplot(1,2,1)\n",
    "plt.imshow(raw_image)\n",
    "a = fig.add_subplot(1,2,2)\n",
    "plt.imshow(result)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.1 Create a standard training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import tensorflow  as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cPickle as pickle\n",
    "from model.datasets.data import generate_standard_dataset\n",
    "\n",
    "# Load Normal and Nude images into the train dataset\n",
    "\n",
    "image_normal_ls, file_name_normal = generate_standard_dataset('/home/cpu11757/workspace/Nudity_Detection/src/model/datasets/train/normal')\n",
    "\n",
    "nudity_ls, file_name_nudity = generate_standard_dataset('/home/cpu11757/workspace/Nudity_Detection/src/model/datasets/train/nude')\n",
    "\n",
    "init_op = tf.initialize_all_variables()\n",
    "\n",
    "labels = np.zeros(3000, dtype = np.uint)\n",
    "\n",
    "\n",
    "database = []\n",
    "with tf.Session() as session:\n",
    "    session.run(init_op)\n",
    "    # Start populating the filename queue\n",
    "    coord = tf.train.Coordinator()\n",
    "    tf.train.start_queue_runners(coord=coord)    \n",
    "    for i in range(3000):\n",
    "        #print i\n",
    "        if i % 2 == 0:\n",
    "            image = image_normal_ls.eval()\n",
    "        else:\n",
    "            image = nudity_ls.eval()\n",
    "            labels[i] = 1\n",
    "        database.append(image)\n",
    "    coord.request_stop()\n",
    "\n",
    "database = np.array(database)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from Dataset.data import generate_standard_dataset\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "img_nudity, _ = generate_standard_dataset('/media/taivu/Data/Project/Nudity_Detection/src/model/datasets/AdditionalDataset/vng/sex')\n",
    "\n",
    "labels = np.ones(100, dtype = np.uint)\n",
    "\n",
    "dataset = []\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    coord = tf.train.Coordinator()\n",
    "    tf.train.start_queue_runners(coord=coord)\n",
    "    \n",
    "    for i in range(100):\n",
    "        image = img_nudity.eval()\n",
    "        dataset.append(image)\n",
    "    coord.request_stop()\n",
    "    \n",
    "database = np.array(dataset)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print file_name_normal[1123]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Generate tfrecords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "def _int64_feature(value):\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "\n",
    "def _bytes_feature(value):\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "def convert_to(data_dir, dataset, labels, name):\n",
    "    \"\"\"Converts a dataset to tfrecords.\"\"\"\n",
    "    images = dataset\n",
    "    labels = labels\n",
    "    num_examples = dataset.shape[0]\n",
    "    \n",
    "    rows, cols, depth = dataset[0].shape\n",
    "    \n",
    "    filename = os.path.join(data_dir, name + '.tfrecords')\n",
    "    \n",
    "    writer = tf.python_io.TFRecordWriter(filename)\n",
    "    \n",
    "    for idx in range(num_examples):\n",
    "        image_raw = images[idx].tostring()\n",
    "        example = tf.train.Example(features = tf.train.Features(feature={\n",
    "                    'height': _int64_feature(rows),\n",
    "                    'width': _int64_feature(cols),\n",
    "                    'depth': _int64_feature(depth),\n",
    "                    'label': _int64_feature(int(labels[idx])),\n",
    "                    'image_raw': _bytes_feature(image_raw)\n",
    "                }))\n",
    "        writer.write(example.SerializeToString())\n",
    "    writer.close()\n",
    "\n",
    "convert_to('/home/taivu/workspace/NudityDetection/Dataset',\n",
    "          database, labels, 'nudity_test_set')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+  Read a batch images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def read_and_decode(filename_queue):\n",
    "    reader = tf.TFRecordReader()\n",
    "    _, serialized_example = reader.read(filename_queue)\n",
    "    features = tf.parse_single_example(\n",
    "    serialized_example,\n",
    "    features={\n",
    "            'image_raw': tf.FixedLenFeature([], tf.string),\n",
    "            'label': tf.FixedLenFeature([], tf.int64),\n",
    "            'depth': tf.FixedLenFeature([], tf.int64),\n",
    "            'width': tf.FixedLenFeature([], tf.int64),\n",
    "            'height': tf.FixedLenFeature([], tf.int64)\n",
    "        })\n",
    "    \n",
    "    image = tf.decode_raw(features['image_raw'], tf.float32)\n",
    "    image = tf.reshape(image,[34,34,3])\n",
    "    label = tf.cast(features['label'], tf.int32)\n",
    "    height = tf.cast(features['height'], tf.int32)\n",
    "    width = tf.cast(features['width'], tf.int32)\n",
    "    depth = tf.cast(features['depth'], tf.int32)\n",
    "    return image, label, height, width, depth\n",
    "\n",
    "def data_input(data_dir, batch_size):\n",
    "    filename_queue = tf.train.string_input_producer([data_dir], num_epochs = None)\n",
    "    image, label, height, width, depth = read_and_decode(filename_queue)\n",
    "    \n",
    "    images_batch, labels_batch = tf.train.shuffle_batch(\n",
    "        [image, label], \n",
    "        batch_size = batch_size,\n",
    "        capacity = 2000,\n",
    "        min_after_dequeue = 80\n",
    "    )\n",
    "    return images_batch, labels_batch\n",
    "\n",
    "\n",
    "#filename_queue = tf.train.string_input_producer(['/home/cpu11757/workspace/Nudity_Detection/src/model/datasets/vng_dataset.tfrecords'], num_epochs = None)\n",
    "#image, label, height,_,depth = read_and_decode(filename_queue)\n",
    "img_batch, lb_batch = data_input('/home/cpu11757/workspace/Nudity_Detection/src/model/datasets/vng_dataset.tfrecords',500)\n",
    "\n",
    "init_op = tf.initialize_all_variables()\n",
    "fig = plt.figure()\n",
    "\n",
    "with tf.Session() as session:\n",
    "    session.run(init_op)\n",
    "    coord = tf.train.Coordinator()\n",
    "    tf.train.start_queue_runners(coord=coord)\n",
    "    images, labels = session.run([img_batch, lb_batch])\n",
    "    coord.request_stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.imshow(images[1])\n",
    "print labels[0]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Example shuffle dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "f = [\"f1\", \"f2\", \"f3\", \"f4\", \"f5\", \"f6\", \"f7\", \"f8\"]\n",
    "l = [\"l1\", \"l2\", \"l3\", \"l4\", \"l5\", \"l6\", \"l7\", \"l8\"]\n",
    "\n",
    "fv = tf.constant(f)\n",
    "lv = tf.constant(l)\n",
    "\n",
    "rsq = tf.RandomShuffleQueue(10, 0, [tf.string, tf.string], shapes=[[],[]])\n",
    "do_enqueues = rsq.enqueue_many([fv, lv])\n",
    "\n",
    "gotf, gotl = rsq.dequeue()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.initialize_all_variables())\n",
    "    coord = tf.train.Coordinator()\n",
    "    tf.train.start_queue_runners(sess=sess,coord = coord)\n",
    "    sess.run(do_enqueues)\n",
    "    for i in xrange(2):\n",
    "        one_f, one_l = sess.run([gotf, gotl])\n",
    "        print \"F: \", one_f, \"L: \", one_l\n",
    "    \n",
    "    coord.request_stop()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Example cPickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cPickle as pickle\n",
    "\n",
    "dict1 = {'name':[],'id':[]}\n",
    "dict2 = {'local':[], 'paza':[]}\n",
    "\n",
    "#with open('test.p', 'wb') as fp:\n",
    "#    pickle.dump(dict1,fp)\n",
    "#    pickle.dump(dict2,fp)\n",
    "    \n",
    "with open('test.p', 'rb') as fp:\n",
    "    d1 = pickle.load(fp)\n",
    "    d2 = pickle.load(fp)\n",
    "\n",
    "print len(d1)\n",
    "print len(d2)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Example reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "a = tf.constant(np.array([[.1]]))\n",
    "init = tf.initialize_all_variables()\n",
    "with tf.Session() as session:\n",
    "    session.run(init)\n",
    "    b = session.run(tf.nn.softmax(a))\n",
    "    c = session.run(tf.nn.softmax_cross_entropy_with_logits([0.6, 0.4],[0,1]))\n",
    "    #print b\n",
    "    #print c\n",
    "\n",
    "label = np.array([[0], [1], [1]])\n",
    "idx = np.arange(3) * 2\n",
    "print ('IDX')\n",
    "print idx\n",
    "\n",
    "labels_one_hot = np.zeros((3,2))\n",
    "print ('labels_one_hot')\n",
    "print labels_one_hot\n",
    "\n",
    "\n",
    "labels_one_hot.flat[idx + label.ravel()] = 1\n",
    "print ('IDX + label.ravel()')\n",
    "print idx + label.ravel()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from Dataset.data import preprocess_image\n",
    "import numpy as np\n",
    "\n",
    "filename_queue = tf.train.string_input_producer(tf.train.match_filenames_once(\n",
    "    '/home/taivu/workspace/NudityDetection/Dataset/train/normal/*.jpg'))\n",
    "\n",
    "img_reader = tf.WholeFileReader()\n",
    "\n",
    "_, img_file = img_reader.read(filename_queue)\n",
    "\n",
    "image = tf.image.decode_jpeg(img_file, 3)\n",
    "\n",
    "image = preprocess_image(image, 34, 34)\n",
    "\n",
    "images = tf.train.batch([image],\n",
    "                       batch_size = 10,\n",
    "                       capacity = 50,\n",
    "                       name = 'input')\n",
    "\n",
    "coord = tf.train.Coordinator()\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    threads = tf.train.start_queue_runners(coord=coord)\n",
    "    \n",
    "    result_img = sess.run([images])\n",
    "    \n",
    "    result_img = np.array(result_img)\n",
    "    \n",
    "    coord.request_stop()\n",
    "    coord.join(threads)\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.imshow(result_img[0][1])\n",
    "plt.show()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 10, 34, 34, 3)\n",
      "float32\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from execute_model import evaluate\n",
    "from Dataset.data import data_input\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "dt, _ = data_input('/home/taivu/workspace/NudityDetection/Dataset/vng_dataset_validation.tfrecords', 10, False)\n",
    "coord = tf.train.Coordinator()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    threads = tf.train.start_queue_runners(coord=coord)\n",
    "    \n",
    "    result_img = sess.run([dt])\n",
    "    coord.request_stop()\n",
    "    coord.join(threads)\n",
    "\n",
    "#fig = plt.figure()\n",
    "result_img = np.array(result_img)\n",
    "print result_img.shape\n",
    "print result_img.dtype\n",
    "#plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 10, 34, 34, 3)\n",
      "float32\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from execute_model import evaluate\n",
    "from Dataset.data import data_input\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "dt = data_input('/home/taivu/workspace/NudityDetection/Dataset/vng_dataset_validation.tfrecords', 10, False, False)\n",
    "coord = tf.train.Coordinator()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    threads = tf.train.start_queue_runners(coord=coord)\n",
    "    \n",
    "    result_img = sess.run([dt])\n",
    "    coord.request_stop()\n",
    "    coord.join(threads)\n",
    "\n",
    "#fig = plt.figure()\n",
    "result_img = np.array(result_img)\n",
    "print result_img.shape\n",
    "print result_img.dtype\n",
    "#plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/taivu/workspace/AddPic/b20.jpg'\n",
      " '/home/taivu/workspace/AddPic/d8.jpg' '/home/taivu/workspace/AddPic/8.jpg']INFO:tensorflow:Error reported to Coordinator: <type 'exceptions.RuntimeError'>, Attempted to use a closed Session.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import glob\n",
    "from Dataset.data import preprocess_image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data_dir = '/home/taivu/workspace/AddPic'\n",
    "\n",
    "filenames = []\n",
    "for pathAndFilename in glob.iglob(os.path.join(data_dir, '*.jpg')):\n",
    "    filenames.append(pathAndFilename)\n",
    "    \n",
    "filename_queue = tf.train.string_input_producer(filenames, shuffle = None)\n",
    "\n",
    "filename = filename_queue.dequeue()\n",
    "\n",
    "# img_reader = tf.WholeFileReader()\n",
    "\n",
    "img_file = tf.read_file(filename)\n",
    "\n",
    "#_, img_file = img_reader.read(filename)\n",
    "\n",
    "img = tf.image.decode_jpeg(img_file, 3)\n",
    "\n",
    "img = preprocess_image(img, 34, 34)\n",
    "\n",
    "filename_batch, img_batch = tf.train.batch([filename, img], batch_size = 3, capacity=200, name = 'input')\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "coord =tf.train.Coordinator()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    tf.train.start_queue_runners(sess, coord)    \n",
    "    ls_img, ls_nf = sess.run([img_batch, filename_batch])\n",
    "    \n",
    "#fig = plt.figure()\n",
    "\n",
    "print ls_nf\n",
    "for i in range(3):\n",
    "    a = fig.add_subplot(1,3, i)\n",
    "    a.set_title('%d'%i)\n",
    "    plt.imshow(ls_img[i])\n",
    "plt.show()\n",
    "\n",
    "\n",
    "    \n",
    "coord.request_stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/taivu/workspace/AddPic/b20.jpg\n"
     ]
    }
   ],
   "source": [
    "print ls_nf[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3, 4, 5, 6]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "a = [[1,2,3]]\n",
    "b = [[4,5,6]]\n",
    "np.column_stack((a,b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "print int(math.ceil(float(5)/3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
