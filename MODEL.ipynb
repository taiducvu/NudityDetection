{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NUDITY DETECTION MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 1: Preprocessing Data\n",
    " Our input images have varied resolution while a model often requires fixed-size inputs so that we need to preprocess them to have a uniform size for our data. To do that, we take two bellow steps:  \n",
    " + Dropping 87.5 per cent of the central region of image\n",
    " + Resizing them into the size $34 \\times 34 \\times 3$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import tensorflow as tf\n",
    "from scipy.misc import imread, imresize\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "from Dataset.data import preprocess_image\n",
    "\n",
    "image = tf.placeholder(\"uint8\", [None, None, 3])\n",
    "result_image = preprocess_image(image, 34, 34)\n",
    "raw_image = imread('/home/taivu/workspace/NudityDetection/Dataset/train/normal/34.jpg')\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    result_img = sess.run(result_image, feed_dict={image:raw_image})\n",
    "\n",
    "################ Plot the raw image and the processed image ##########################\n",
    "gs = gridspec.GridSpec(1, 2, width_ratios=[3, 2]) \n",
    "\n",
    "fig = plt.figure()\n",
    "a1 = fig.add_subplot(gs[0])\n",
    "a1.set_title(\"Raw image\")\n",
    "plt.imshow(raw_image)\n",
    "a2 = fig.add_subplot(gs[1])\n",
    "a2.set_title(\"Processed image\")\n",
    "plt.imshow(result_img, shape =(34, 34))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 2: Build a model\n",
    "  The model consists of 6 hidden layers including 2 convolutional layers, 2 pool layers, and 2 fully-connected layers. The detail of model are shown in the bellow figure\n",
    "![NUDITY DETECTION MODE](model.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stage 2.1: Training the model\n",
    "  + To training this model, we used a training set with 4000 images with the ratio of nudity to normal images is 1:1. In additional, we alse estimated the model in the training process using a validation set with 2000 images with the ratio is similar to the training.\n",
    "  + **Cross-entropy** is the loss function to assesses the difference between the predicted labels of model and the real labels of samples. Its notation: $L$\n",
    "  $$ L = - \\log\\left ( \\frac{e^{f_y}}{\\sum_{j}e^{f_j}} \\right ) $$ in which, $f_y$ is the activation of neuron that present the real class of a sample\n",
    "  + **Mini-batch Gradient Descent** algorithm is used to optimize the weights of the model\n",
    "  $$\\mathit{w}_{t} = \\mathit{w}_{t-1} - \\alpha \\frac{1}{m} \\frac{\\partial L}{\\partial w}$$ in which $\\mathit{w}_{t}$ is the weights of model at time $t$ of the optimizing process.\n",
    "  + The hyper-parameters of model such as the number of images in each mini-batch $m$, learning rate $\\alpha$ are set empirically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from vng_train import train\n",
    "\n",
    "# Do train the model\n",
    "train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stage 2.2: Run the model\n",
    " + After the training process, the trained weights of model are saved into a hard drive to reuse in the future\n",
    " + To run the model, we need to re-construct the model and then load the trained weights into it so that the model will not optimize again its weights in this stage. After the input images are feed-forward via the model, it will only classify them into two classes (*Nudity* or *Normal*) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from execute_model import evaluate\n",
    "\n",
    "# Evaluate the model\n",
    "img, pre_lb, real_lb = evaluate()\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(20,20))\n",
    "\n",
    "for i in range(50):\n",
    "    a = fig.add_subplot(10,5, i)\n",
    "    a.set_title('PL:%d'%(pre_lb[i]))\n",
    "    a.set_yticklabels([])\n",
    "    a.set_xticklabels([])\n",
    "    plt.imshow(img[i])\n",
    "plt.pause(1)\n",
    "plt.show()\n",
    "\n",
    "#print pre_lb\n",
    "#print real_lb\n",
    "num_err = np.absolute(pre_lb - real_lb)\n",
    "print('The number of error samples: %d'%np.sum(num_err))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from execute_model import evaluate\n",
    "import numpy as np\n",
    "\n",
    "# Evaluate the model\n",
    "img, pre_lb, real_lb = evaluate('/home/taivu/workspace/NudityDetection/Dataset/normal_test_set.tfrecords')\n",
    "#print('Predicted labels: ',pre_lb)\n",
    "#print('Real labels: ',real_lb)\n",
    "\n",
    "fig = plt.figure(figsize=(20,20))\n",
    "for i in range(50):\n",
    "    a = fig.add_subplot(10,5, i)\n",
    "    a.set_title('PL:%d'%(pre_lb[i]))\n",
    "    a.set_yticklabels([])\n",
    "    a.set_xticklabels([])\n",
    "    plt.imshow(img[i])\n",
    "plt.show()\n",
    "\n",
    "num_err = np.absolute(pre_lb - real_lb)\n",
    "print('The number of error samples: %d'%np.sum(num_err))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from execute_model import evaluate\n",
    "\n",
    "# Evaluate the model\n",
    "img, pre_lb, real_lb = evaluate('/home/taivu/workspace/NudityDetection/Dataset/nudity_test_set.tfrecords', False)\n",
    "\n",
    "fig = plt.figure(figsize=(20,20))\n",
    "\n",
    "for i in range(50):\n",
    "    a = fig.add_subplot(10,5, i)\n",
    "    a.set_title('PL:%d'%(pre_lb[i]))\n",
    "    a.set_yticklabels([])\n",
    "    a.set_xticklabels([])\n",
    "    plt.imshow(img[i])\n",
    "plt.show()\n",
    "\n",
    "num_err = np.absolute(pre_lb - real_lb)\n",
    "print('The number of error samples: %d'%np.sum(num_err))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "############################PIPELINE INPUT DATA########################################\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from execute_model import evaluate\n",
    "import numpy as np\n",
    "\n",
    "eval_img, pre_label, _ = evaluate('/home/taivu/workspace/AddPic', True)\n",
    "\n",
    "#fig = plt.figure(figsize=(40,80))\n",
    "\n",
    "#for i in range(80):\n",
    "#    a = fig.add_subplot(16,5, i)\n",
    "#    a.set_title('PL:%d'%(pre_label[i]))\n",
    "#    a.set_yticklabels([])\n",
    "#    a.set_xticklabels([])\n",
    "#    plt.imshow(eval_img[i])\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 3: Optimize the model\n",
    "+ Apply Transfer Learning method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "(1.0, 310.90027)\n"
     ]
    }
   ],
   "source": [
    "# Test program\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from test_program import test_program\n",
    "\n",
    "test_program()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
